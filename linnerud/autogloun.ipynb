{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58e0d7686f02376d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:24:02.119667700Z",
     "start_time": "2024-02-28T15:23:47.072200900Z"
    }
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.datasets import load_linnerud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30518dfc3c57bb79",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T15:30:44.244358100Z",
     "start_time": "2024-02-28T15:27:41.540415300Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m X \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mdata\n\u001B[0;32m      3\u001B[0m Y \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mtarget\n\u001B[1;32m----> 5\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mTabularDataset\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m test_data \u001B[38;5;241m=\u001B[39m TabularDataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m train_data\u001B[38;5;241m.\u001B[39mhead()\n",
      "Cell \u001B[1;32mIn[3], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m X \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mdata\n\u001B[0;32m      3\u001B[0m Y \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mtarget\n\u001B[1;32m----> 5\u001B[0m train_data \u001B[38;5;241m=\u001B[39m \u001B[43mTabularDataset\u001B[49m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m test_data \u001B[38;5;241m=\u001B[39m TabularDataset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTest.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m train_data\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\PyCharm Professional\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data = load_linnerud(as_frame=True)\n",
    "X = data.data\n",
    "Y = data.target\n",
    "\n",
    "train_data, test_data = train_test_split()\n",
    "train_data = TabularDataset('Train.csv')\n",
    "test_data = TabularDataset('Test.csv')\n",
    "\n",
    "\n",
    "train_data.head()\n",
    "\n",
    "label = 'label'\n",
    "train_data[label].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfba6a4205bcebdc",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T15:54:48.297422500Z",
     "start_time": "2024-02-27T15:54:48.226424400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    13931.000000\nmean      1140.577274\nstd       1081.964648\nmin          0.000000\n25%        259.000000\n50%        842.000000\n75%       1663.000000\nmax       7860.000000\nName: cnt, dtype: float64"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogloun_model/\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./autogloun_model/\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          8\n",
      "Memory Avail:       14.97 GB / 31.85 GB (47.0%)\n",
      "Disk Space Avail:   765.49 GB / 940.03 GB (81.4%)\n",
      "===================================================\n",
      "Train Data Rows:    13931\n",
      "Train Data Columns: 8\n",
      "Label Column:       cnt\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15317.10 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.85 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 8 | ['t1', 't2', 'hum', 'wind_speed', 'weather_code', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 6 | ['t1', 't2', 'hum', 'wind_speed', 'weather_code', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['is_holiday', 'is_weekend']\n",
      "\t0.2s = Fit runtime\n",
      "\t8 features in original data used to generate 8 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.66 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 12537, Val Rows: 1394\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-978.2348\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-985.836\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-862.5254\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-864.2031\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-903.8458\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.38s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-862.0143\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-889.043\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.4s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-862.0073\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.6s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-862.6766\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-888.3598\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-864.16\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'ExtraTreesMSE': 0.313, 'NeuralNetFastAI': 0.277, 'CatBoost': 0.205, 'NeuralNetTorch': 0.108, 'XGBoost': 0.096}\n",
      "\t-851.1936\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.31s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 54.47s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./autogloun_model/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).load(path=\"./AutogluonModels/ag-20231215_150640\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:07:20.595501Z",
     "start_time": "2024-02-27T16:06:25.900647900Z"
    }
   },
   "id": "b7014ee3327dcfd8"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219c26018c7fbeef",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:19:06.392354500Z",
     "start_time": "2024-02-27T16:19:06.336104Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_data.drop(columns=[label]))\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd75517906b275bd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:21:45.528539200Z",
     "start_time": "2024-02-27T16:21:45.432531700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "14999     201\n5504      867\n10259    1435\n15150    1566\n345       693\nName: cnt, dtype: int64"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60df8f7f5872ed15",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:20:59.333819900Z",
     "start_time": "2024-02-27T16:20:58.214435900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "14999     727.184204\n5504     1056.075317\n10259    1249.485840\n15150    1785.752197\n345       201.123642\nName: cnt, dtype: float32"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "{'root_mean_squared_error': -864.7775674115269,\n 'mean_squared_error': -747840.241098198,\n 'mean_absolute_error': -608.0744023789903,\n 'r2': 0.3791673724300947,\n 'pearsonr': 0.6166151071994901,\n 'median_absolute_error': -434.9698486328125}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def wrapped_model(x):\n",
    "    column_names = [f'column_{i}' for i in range(12)]\n",
    "    x = pd.DataFrame(x)\n",
    "    x.columns = column_names\n",
    "    preds = predictor.predict(x).to_numpy()\n",
    "        \n",
    "    return preds\n",
    "\n",
    "test_data = TabularDataset('Test.csv')\n",
    "\n",
    "to_be_explained = pd.DataFrame(test_data).drop('label', axis=1).to_numpy()[0]\n",
    "explainer = shap.KernelExplainer(wrapped_model, pd.read_csv('./Train.csv').drop('label', axis=1).sample(n=100))\n",
    "shap_values = explainer.shap_values(to_be_explained)\n",
    "relevance = abs(shap_values.ravel())\n",
    "\n",
    "\n",
    "norm_relevance = ((relevance - min(relevance)) / (max(relevance) - min(relevance)))\n",
    "\n",
    "print(relevance)\n",
    "plt.imshow(norm_relevance.reshape((2, 6)))\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:22:07.243709900Z",
     "start_time": "2024-02-27T16:22:06.161711400Z"
    }
   },
   "id": "53fa8c49c9979333"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                  model   score_test   score_val              eval_metric  \\\n0   WeightedEnsemble_L2  -864.777567 -851.193578  root_mean_squared_error   \n1       NeuralNetFastAI  -871.452567 -862.007270  root_mean_squared_error   \n2              CatBoost  -874.392598 -862.014261  root_mean_squared_error   \n3               XGBoost  -874.580263 -862.676594  root_mean_squared_error   \n4            LightGBMXT  -874.625472 -862.525423  root_mean_squared_error   \n5              LightGBM  -877.855435 -864.203128  root_mean_squared_error   \n6         LightGBMLarge  -880.022788 -864.160039  root_mean_squared_error   \n7        NeuralNetTorch  -907.496117 -888.359756  root_mean_squared_error   \n8         ExtraTreesMSE  -911.525525 -889.042982  root_mean_squared_error   \n9       RandomForestMSE  -928.204409 -903.845828  root_mean_squared_error   \n10       KNeighborsUnif -1000.851881 -978.234814  root_mean_squared_error   \n11       KNeighborsDist -1028.123800 -985.836040  root_mean_squared_error   \n\n    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n0         1.108070       0.248980  41.171174                 0.005999   \n1         0.148617       0.023000  15.598369                 0.148617   \n2         0.059017       0.002981   1.606015                 0.059017   \n3         0.030994       0.005999   0.842525                 0.030994   \n4         0.054903       0.013001   1.533518                 0.054903   \n5         0.014000       0.006999   0.965998                 0.014000   \n6         0.023000       0.010999   1.474072                 0.023000   \n7         0.037001       0.011000  18.416183                 0.037001   \n8         0.826442       0.202999   4.401082                 0.826442   \n9         0.835002       0.186997   6.382169                 0.835002   \n10        0.057000       0.040998   0.054002                 0.057000   \n11        0.064250       0.034317   0.049004                 0.064250   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 0.003001           0.307000            2       True   \n1                 0.023000          15.598369            1       True   \n2                 0.002981           1.606015            1       True   \n3                 0.005999           0.842525            1       True   \n4                 0.013001           1.533518            1       True   \n5                 0.006999           0.965998            1       True   \n6                 0.010999           1.474072            1       True   \n7                 0.011000          18.416183            1       True   \n8                 0.202999           4.401082            1       True   \n9                 0.186997           6.382169            1       True   \n10                0.040998           0.054002            1       True   \n11                0.034317           0.049004            1       True   \n\n    fit_order  \n0          12  \n1           8  \n2           6  \n3           9  \n4           3  \n5           4  \n6          11  \n7          10  \n8           7  \n9           5  \n10          1  \n11          2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_test</th>\n      <th>score_val</th>\n      <th>eval_metric</th>\n      <th>pred_time_test</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_test_marginal</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-864.777567</td>\n      <td>-851.193578</td>\n      <td>root_mean_squared_error</td>\n      <td>1.108070</td>\n      <td>0.248980</td>\n      <td>41.171174</td>\n      <td>0.005999</td>\n      <td>0.003001</td>\n      <td>0.307000</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NeuralNetFastAI</td>\n      <td>-871.452567</td>\n      <td>-862.007270</td>\n      <td>root_mean_squared_error</td>\n      <td>0.148617</td>\n      <td>0.023000</td>\n      <td>15.598369</td>\n      <td>0.148617</td>\n      <td>0.023000</td>\n      <td>15.598369</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CatBoost</td>\n      <td>-874.392598</td>\n      <td>-862.014261</td>\n      <td>root_mean_squared_error</td>\n      <td>0.059017</td>\n      <td>0.002981</td>\n      <td>1.606015</td>\n      <td>0.059017</td>\n      <td>0.002981</td>\n      <td>1.606015</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>-874.580263</td>\n      <td>-862.676594</td>\n      <td>root_mean_squared_error</td>\n      <td>0.030994</td>\n      <td>0.005999</td>\n      <td>0.842525</td>\n      <td>0.030994</td>\n      <td>0.005999</td>\n      <td>0.842525</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBMXT</td>\n      <td>-874.625472</td>\n      <td>-862.525423</td>\n      <td>root_mean_squared_error</td>\n      <td>0.054903</td>\n      <td>0.013001</td>\n      <td>1.533518</td>\n      <td>0.054903</td>\n      <td>0.013001</td>\n      <td>1.533518</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>-877.855435</td>\n      <td>-864.203128</td>\n      <td>root_mean_squared_error</td>\n      <td>0.014000</td>\n      <td>0.006999</td>\n      <td>0.965998</td>\n      <td>0.014000</td>\n      <td>0.006999</td>\n      <td>0.965998</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMLarge</td>\n      <td>-880.022788</td>\n      <td>-864.160039</td>\n      <td>root_mean_squared_error</td>\n      <td>0.023000</td>\n      <td>0.010999</td>\n      <td>1.474072</td>\n      <td>0.023000</td>\n      <td>0.010999</td>\n      <td>1.474072</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NeuralNetTorch</td>\n      <td>-907.496117</td>\n      <td>-888.359756</td>\n      <td>root_mean_squared_error</td>\n      <td>0.037001</td>\n      <td>0.011000</td>\n      <td>18.416183</td>\n      <td>0.037001</td>\n      <td>0.011000</td>\n      <td>18.416183</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ExtraTreesMSE</td>\n      <td>-911.525525</td>\n      <td>-889.042982</td>\n      <td>root_mean_squared_error</td>\n      <td>0.826442</td>\n      <td>0.202999</td>\n      <td>4.401082</td>\n      <td>0.826442</td>\n      <td>0.202999</td>\n      <td>4.401082</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>RandomForestMSE</td>\n      <td>-928.204409</td>\n      <td>-903.845828</td>\n      <td>root_mean_squared_error</td>\n      <td>0.835002</td>\n      <td>0.186997</td>\n      <td>6.382169</td>\n      <td>0.835002</td>\n      <td>0.186997</td>\n      <td>6.382169</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KNeighborsUnif</td>\n      <td>-1000.851881</td>\n      <td>-978.234814</td>\n      <td>root_mean_squared_error</td>\n      <td>0.057000</td>\n      <td>0.040998</td>\n      <td>0.054002</td>\n      <td>0.057000</td>\n      <td>0.040998</td>\n      <td>0.054002</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>KNeighborsDist</td>\n      <td>-1028.123800</td>\n      <td>-985.836040</td>\n      <td>root_mean_squared_error</td>\n      <td>0.064250</td>\n      <td>0.034317</td>\n      <td>0.049004</td>\n      <td>0.064250</td>\n      <td>0.034317</td>\n      <td>0.049004</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def wrapped_net(x):\n",
    "    column_names = [f'column_{i}' for i in range(12)]\n",
    "    x = pd.DataFrame(x)\n",
    "    x.columns = column_names\n",
    "    preds = predictor.predict_proba(x).to_numpy()\n",
    "        \n",
    "    return preds\n",
    "\n",
    "background = pd.read_csv('./Train.csv').drop('label', axis=1).sample(n=100).to_numpy()\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    background,\n",
    "    feature_names=[str(i) for i in range(12)],\n",
    "    verbose=True,\n",
    "    mode='classification',\n",
    ")\n",
    "\n",
    "test = pd.read_csv('./Train.csv').drop('label', axis=1).to_numpy()[0]\n",
    "\n",
    "exp = explainer.explain_instance(test, wrapped_net, num_features=12)\n",
    "# exp.save_to_file('lime_explanationall.html')\n",
    "# relevance = abs(np.asarray([float(i) for i in exp.domain_mapper.feature_values]))\n",
    "relevance = abs(np.asarray([j for i, j in sorted(exp.local_exp[1], key=lambda i: i[0])]))\n",
    "# relevance = exp.local_exp[1]\n",
    "norm_relevance = ((relevance - min(relevance)) / (max(relevance) - min(relevance)))\n",
    "\n",
    "\n",
    "print(relevance)\n",
    "plt.imshow(norm_relevance.reshape((2, 6)))\n",
    "plt.colorbar()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T16:22:15.816129100Z",
     "start_time": "2024-02-27T16:22:13.541899200Z"
    }
   },
   "id": "560f722e3a940959"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "109f45bf49d7a772"
  }
 ],
 "metadata": {
  "authors": [],
  "date": "",
  "title": "Allegato A: Autogloun test for gender detection",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
